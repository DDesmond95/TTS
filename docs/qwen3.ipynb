{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a849f28f",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "1. `pip install qwen-tts`\n",
    "2. `pip uninstall -y torch torchaudio torchvision`\n",
    "3. `conda install pytorch torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155df9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"PYTORCH_SDP_ENABLED\"] = \"0\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"0\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f81783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "\n",
    "\n",
    "print(\"Torch CUDA runtime:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"Capability:\", torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdc445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819e232c",
   "metadata": {},
   "source": [
    "### Install SOX\n",
    "\n",
    "#### Step 1ï¸âƒ£ Download SoX (official source)\n",
    "\n",
    "Go here (official, no tricks):\n",
    "\n",
    "ğŸ‘‰ [http://sox.sourceforge.net/](http://sox.sourceforge.net/)\n",
    "\n",
    "Click **â€œDownload SoX for Windowsâ€**\n",
    "Get the **Windows binary installer** (usually `sox-14.4.x-win32.exe` or similar).\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2ï¸âƒ£ Install it (IMPORTANT options)\n",
    "\n",
    "During installation:\n",
    "\n",
    "- âœ… **Check â€œAdd SoX to PATHâ€**\n",
    "- Leave everything else default\n",
    "- Finish install\n",
    "\n",
    "This PATH checkbox is the most important part.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3ï¸âƒ£ Verify SoX works (outside Python)\n",
    "\n",
    "Open a **new terminal** (important), then run:\n",
    "\n",
    "```bat\n",
    "sox --version\n",
    "```\n",
    "\n",
    "Expected output (example):\n",
    "\n",
    "```\n",
    "sox: SoX v14.4.2\n",
    "```\n",
    "\n",
    "If you see that â†’ SoX is installed correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "import gc\n",
    "\n",
    "# -----------------------------\n",
    "# Environment info\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(\"===== ENVIRONMENT =====\")\n",
    "print(\"Device selected :\", device)\n",
    "print(\"Torch version   :\", torch.__version__)\n",
    "print(\"CUDA available  :\", torch.cuda.is_available())\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(\"CUDA version    :\", torch.version.cuda)\n",
    "    print(\"GPU name        :\", torch.cuda.get_device_name(0))\n",
    "    print(\n",
    "        \"GPU memory (GB) :\",\n",
    "        round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2),\n",
    "    )\n",
    "print(\"=======================\\n\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model loader with full prints\n",
    "# -----------------------------\n",
    "def load_model(kind: str):\n",
    "    print(f\"\\n===== LOADING MODEL ({kind.upper()}) =====\")\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(\"CUDA cache cleared\")\n",
    "\n",
    "    if kind == \"base\":\n",
    "        model_path = \"./models/Qwen3-TTS-12Hz-1.7B-Base\"\n",
    "    elif kind == \"custom\":\n",
    "        model_path = \"./models/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'base' or 'custom'\")\n",
    "\n",
    "    print(\"Model path      :\", model_path)\n",
    "    print(\"Torch dtype     :\", dtype)\n",
    "\n",
    "    model = Qwen3TTSModel.from_pretrained(\n",
    "        model_path,\n",
    "        dtype=dtype,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Supported languages\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        langs = model.get_supported_languages()\n",
    "        print(\"Supported languages:\")\n",
    "        for lang in langs:\n",
    "            print(\" -\", lang)\n",
    "    except Exception as e:\n",
    "        print(\"Could not query supported languages:\", e)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Supported speakers (CustomVoice only)\n",
    "    # -----------------------------\n",
    "    try:\n",
    "        speakers = model.get_supported_speakers()\n",
    "        if speakers:\n",
    "            print(\"Supported speakers:\")\n",
    "            for spk in speakers:\n",
    "                print(\" -\", spk)\n",
    "        else:\n",
    "            print(\"Supported speakers: None (Base model)\")\n",
    "    except Exception:\n",
    "        print(\"Supported speakers: Not available for this model\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # VRAM usage\n",
    "    # -----------------------------\n",
    "    if device == \"cuda\":\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        peak = torch.cuda.max_memory_allocated(0) / 1024**3\n",
    "\n",
    "        print(f\"VRAM allocated  : {allocated:.2f} GB\")\n",
    "        print(f\"VRAM reserved   : {reserved:.2f} GB\")\n",
    "        print(f\"VRAM peak       : {peak:.2f} GB\")\n",
    "\n",
    "    print(\"Model loaded âœ”\")\n",
    "    print(\"=================================\\n\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model unload helper\n",
    "# -----------------------------\n",
    "def unload_model(model=None, name: str = \"\"):\n",
    "    print(f\"\\n===== UNLOADING MODEL {name.upper()} =====\")\n",
    "\n",
    "    if model is not None:\n",
    "        try:\n",
    "            del model\n",
    "            print(\"Model object deleted\")\n",
    "        except Exception as e:\n",
    "            print(\"Model delete warning:\", e)\n",
    "\n",
    "    gc.collect()\n",
    "    print(\"Python GC collected\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        print(\"CUDA cache cleared\")\n",
    "        print(\n",
    "            \"VRAM after cleanup:\",\n",
    "            f\"{torch.cuda.memory_allocated(0) / 1024**3:.2f} GB allocated\",\n",
    "        )\n",
    "\n",
    "    print(\"====================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0da126",
   "metadata": {},
   "outputs": [],
   "source": [
    "unload_model(model, name=\"base\")\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92e0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CustomVoice\n",
    "model = load_model(\"custom\")\n",
    "speakers = model.get_supported_speakers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def run_generate_custom_voice(\n",
    "    model,\n",
    "    text,\n",
    "    speaker,\n",
    "    output_path,\n",
    "    language=\"auto\",\n",
    "    instruct=None,\n",
    "    generation_kwargs=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Explicit runner for Qwen3 CustomVoice TTS.\n",
    "\n",
    "    This function does NOT inject defaults or modify user intent.\n",
    "    All generation behavior is controlled by the caller.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Qwen3TTSModel\n",
    "        Loaded CustomVoice model.\n",
    "    text : str or list[str]\n",
    "        Text(s) to synthesize.\n",
    "    speaker : str or list[str]\n",
    "        Speaker name(s), must match model.get_supported_speakers().\n",
    "    output_path : str or Path\n",
    "        Output WAV file (single) or directory (batch).\n",
    "    language : str or list[str], default=\"auto\"\n",
    "        Language(s). Use \"auto\" for multilingual sentences.\n",
    "    instruct : str or list[str] or None\n",
    "        Optional style / emotion instruction(s).\n",
    "    generation_kwargs : dict or None\n",
    "        Extra kwargs passed directly to model.generate_custom_voice().\n",
    "        (Nothing is added automatically.)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n===== RUN generate_custom_voice =====\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Determine mode\n",
    "    # -----------------------------\n",
    "    is_batch = isinstance(text, list)\n",
    "\n",
    "    def ensure_list(value):\n",
    "        return value if isinstance(value, list) else [value]\n",
    "\n",
    "    text_list = ensure_list(text)\n",
    "    speaker_list = ensure_list(speaker)\n",
    "    language_list = ensure_list(language)\n",
    "    instruct_list = ensure_list(instruct) if instruct is not None else None\n",
    "\n",
    "    sample_count = len(text_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Length validation\n",
    "    # -----------------------------\n",
    "    def validate_length(values, name):\n",
    "        if values is not None and len(values) != sample_count:\n",
    "            raise ValueError(\n",
    "                f\"{name} count mismatch: got {len(values)}, expected {sample_count}\"\n",
    "            )\n",
    "\n",
    "    validate_length(speaker_list, \"Speaker\")\n",
    "    validate_length(language_list, \"Language\")\n",
    "    validate_length(instruct_list, \"Instruct\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validate speaker & language\n",
    "    # -----------------------------\n",
    "    supported_speakers = set(model.get_supported_speakers())\n",
    "    supported_languages = set(model.get_supported_languages())\n",
    "\n",
    "    for spk in speaker_list:\n",
    "        if spk not in supported_speakers:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported speaker '{spk}'. \"\n",
    "                f\"Supported speakers: {sorted(supported_speakers)}\"\n",
    "            )\n",
    "\n",
    "    for lang in language_list:\n",
    "        if lang not in supported_languages:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported language '{lang}'. \"\n",
    "                f\"Supported languages: {sorted(supported_languages)}\"\n",
    "            )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Generation kwargs (explicit only)\n",
    "    # -----------------------------\n",
    "    if generation_kwargs is None:\n",
    "        generation_kwargs = {}\n",
    "\n",
    "    # -----------------------------\n",
    "    # Output handling\n",
    "    # -----------------------------\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    if is_batch:\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # User-facing summary\n",
    "    # -----------------------------\n",
    "    print(\"Batch mode        :\", is_batch)\n",
    "    print(\"Number of samples :\", sample_count)\n",
    "    print(\"Speaker(s)        :\", speaker_list if is_batch else speaker_list[0])\n",
    "    print(\"Language(s)       :\", language_list if is_batch else language_list[0])\n",
    "    print(\"Instruct          :\", instruct_list if instruct_list else \"None\")\n",
    "    print(\"Output path       :\", output_path.resolve())\n",
    "    print(\"Generation kwargs :\", generation_kwargs)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Generate audio\n",
    "    # -----------------------------\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        wavs, sample_rate = model.generate_custom_voice(\n",
    "            text=text_list if is_batch else text_list[0],\n",
    "            speaker=speaker_list if is_batch else speaker_list[0],\n",
    "            language=language_list if is_batch else language_list[0],\n",
    "            instruct=instruct_list if instruct_list is not None else None,\n",
    "            **generation_kwargs,\n",
    "        )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save results\n",
    "    # -----------------------------\n",
    "    if is_batch:\n",
    "        for index, waveform in enumerate(wavs):\n",
    "            output_file = output_path / f\"custom_voice_{index}.wav\"\n",
    "            sf.write(output_file, waveform, sample_rate)\n",
    "            print(\"Saved:\", output_file)\n",
    "    else:\n",
    "        sf.write(output_path, wavs[0], sample_rate)\n",
    "        print(\"Saved:\", output_path)\n",
    "\n",
    "    print(\"====================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c864a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Hello everyone, today I want to show you something very interesting. \"\n",
    "    \"è¿™ä¸ªæ¨¡å‹çœŸçš„å¾ˆå‰å®³ï¼Œboleh cakap English, Bahasa Melayu, \"\n",
    "    \"dan ä¸­æ–‡ together without any awkward pause. \"\n",
    "    \"Kalau di Sarawak, orang akan cakap macam ni: \"\n",
    "    \"'Aok, sik ada masalah bah, kitak rilek jak.' \"\n",
    "    \"æ„æ€æ˜¯è¯´ï¼Œeverything is okay, no need to worry. \"\n",
    "    \"You see ah, this kind of multilingual speech synthesis \"\n",
    "    \"memang power, boleh campur bahasa ikut situasi. \"\n",
    "    \"ä¸æ˜¯åˆ»æ„çš„é‚£ç§ï¼Œè€Œæ˜¯è‡ªç„¶æµç•…ã€‚\"\n",
    ")\n",
    "\n",
    "\n",
    "run_generate_custom_voice(\n",
    "    model=model,\n",
    "    text=text,\n",
    "    speaker=\"ryan\",\n",
    "    language=\"auto\",\n",
    "    output_path=\"outputs/multilang_ryan.wav\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4619b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a9309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550db3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload CustomVoice\n",
    "unload_model(model, name=\"custom\")\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefcf34",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124c5263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********\n",
      "Warning: flash-attn is not installed. Will only run the manual PyTorch version. Please install flash-attn for faster inference.\n",
      "********\n",
      " \n",
      "===== RUNTIME CONFIG =====\n",
      "Device      : cuda\n",
      "DType       : torch.float16\n",
      "Attention   : eager\n",
      "GPU         : NVIDIA GeForce GTX 1660 Ti\n",
      "Capability  : (7, 5)\n",
      "==========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*flash attention.*\")\n",
    "\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "\n",
    "\n",
    "def select_runtime():\n",
    "    if not torch.cuda.is_available():\n",
    "        return {\n",
    "            \"device\": \"cpu\",\n",
    "            \"dtype\": torch.float32,\n",
    "            \"attn_impl\": \"eager\",\n",
    "        }\n",
    "\n",
    "    major, minor = torch.cuda.get_device_capability(0)\n",
    "\n",
    "    # Ampere+ (sm >= 80)\n",
    "    if major >= 8:\n",
    "        return {\n",
    "            \"device\": \"cuda\",\n",
    "            \"dtype\": torch.float16,  # bf16 optional if you prefer\n",
    "            \"attn_impl\": \"flash_attention_2\",\n",
    "        }\n",
    "\n",
    "    # Turing / Pascal\n",
    "    return {\n",
    "        \"device\": \"cuda\",\n",
    "        \"dtype\": torch.float16,\n",
    "        \"attn_impl\": \"eager\",\n",
    "    }\n",
    "\n",
    "\n",
    "runtime = select_runtime()\n",
    "\n",
    "print(\"===== RUNTIME CONFIG =====\")\n",
    "print(\"Device      :\", runtime[\"device\"])\n",
    "print(\"DType       :\", runtime[\"dtype\"])\n",
    "print(\"Attention   :\", runtime[\"attn_impl\"])\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU         :\", torch.cuda.get_device_name(0))\n",
    "    print(\"Capability  :\", torch.cuda.get_device_capability(0))\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "MODEL_PATH = \"./models/Qwen3-TTS-12Hz-1.7B-VoiceDesign\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "tts = Qwen3TTSModel.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"cuda:0\",\n",
    "    dtype=runtime[\"dtype\"],\n",
    "    attn_implementation=runtime[\"attn_impl\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Single --------\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "t0 = time.time()\n",
    "\n",
    "text = (\n",
    "    \"å“¥å“¥ï¼Œä½ å›æ¥å•¦ï¼ŸIâ€™ve been waiting for you so long alreadyï¼Œ\"\n",
    "    \"sampaiäººå®¶éƒ½å¼€å§‹æƒ³ä½ äº†ã€‚\"\n",
    "    \"Really, you know? æ¯ä¸€åˆ†é’Ÿéƒ½è§‰å¾—ç‰¹åˆ«æ…¢ï¼Œ\"\n",
    "    \"macam masa tak mahu jalanã€‚\\n\\n\"\n",
    "    \"When I heard your footsteps just nowï¼Œ\"\n",
    "    \"æˆ‘å¿ƒé‡Œä¸€ä¸‹å­å°±äº®èµ·æ¥äº†ï¼Œterus rasaå®‰å¿ƒã€‚\"\n",
    "    \"Youâ€™re finally here, kan? Jangan pergi lagi lahï¼Œ\"\n",
    "    \"stay with me for a whileã€‚\\n\\n\"\n",
    "    \"å“¥å“¥ï¼ŒæŠ±æˆ‘ä¸€ä¸‹å¥½ä¸å¥½ï¼ŸJust a little bitï¼Œkejap sajaã€‚\"\n",
    "    \"æˆ‘ promise ä¸åµä½ ï¼Œåªæƒ³é ç€ä½ ï¼Œ\"\n",
    "    \"å¬ä½ å‘¼å¸çš„å£°éŸ³ã€‚\\n\\n\"\n",
    "    \"Everything feels okay nowã€‚\"\n",
    "    \"æœ‰ä½ åœ¨ï¼Œä»€ä¹ˆéƒ½ä¸æ€•äº†ã€‚\"\n",
    ")\n",
    "\n",
    "\n",
    "wavs, sr = tts.generate_voice_design(\n",
    "    text=text,\n",
    "    language=\"auto\",\n",
    "    instruct=(\n",
    "        \"Soft, intimate and slightly playful young female voice. \"\n",
    "        \"Tone is affectionate and clingy, with gentle pitch rises. \"\n",
    "        \"Chinese lines should sound natural and warm, \"\n",
    "        \"English calm and emotional, \"\n",
    "        \"Malay casual and light, as if speaking softly to someone very close.\"\n",
    "    ),\n",
    "    # temperature=0.7,\n",
    "    # top_p=0.9,\n",
    "    # subtalker_temperature=0.7,\n",
    "    # repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "print(f\"[VoiceDesign Single] time: {t1 - t0:.3f}s\")\n",
    "\n",
    "sf.write(\"qwen3_tts_test_voice_design_single.wav\", wavs[0], sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62631268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VoiceDesign Batch] time: 88.505s\n"
     ]
    }
   ],
   "source": [
    "tts.model.speech_tokenizer.model.decoder.pre_transformer.has_sliding_layers = False\n",
    "for layer in tts.model.speech_tokenizer.model.decoder.pre_transformer.layers:\n",
    "    layer.attention_type = \"full_attention\"\n",
    "\n",
    "\n",
    "# -------- Batch --------\n",
    "texts = [\n",
    "    # --- Sample 1: Chinese + English + Malay (clingy / cute) ---\n",
    "    (\n",
    "        \"å“¥å“¥ï¼Œä½ ç»ˆäºå›æ¥å•¦ã€‚I waited for you for so long alreadyï¼Œ\"\n",
    "        \"sampaiäººå®¶éƒ½æœ‰ç‚¹å§”å±ˆäº†ã€‚\\n\\n\"\n",
    "        \"When youâ€™re not aroundï¼Œ\"\n",
    "        \"æ—¶é—´èµ°å¾—ç‰¹åˆ«æ…¢ï¼Œmacam duniaåœä¸‹æ¥ä¸€æ ·ã€‚\\n\\n\"\n",
    "        \"ç°åœ¨ä½ åœ¨è¿™é‡Œäº†ï¼Œ\"\n",
    "        \"æˆ‘å¿ƒå°±å®‰äº†ã€‚å“¥å“¥ï¼ŒæŠ±ä¸€ä¸‹ï¼Œå¥½ä¸å¥½ï¼Ÿ\"\n",
    "    ),\n",
    "    # --- Sample 2: English + Malay (soft emotional) ---\n",
    "    (\n",
    "        \"I didnâ€™t think you would come back so soon.\\n\"\n",
    "        \"But when I saw youï¼Œ\"\n",
    "        \"terus rasa legaã€‚\\n\\n\"\n",
    "        \"Just stay for a bitï¼Œokayï¼Ÿ\"\n",
    "        \"Jangan pergi lagiã€‚\"\n",
    "    ),\n",
    "    # --- Sample 3: Chinese-dominant with light English ---\n",
    "    (\n",
    "        \"ä»Šå¤©çœŸçš„æœ‰ç‚¹ç´¯äº†ã€‚\\n\"\n",
    "        \"But hearing your voiceï¼Œ\"\n",
    "        \"çªç„¶å°±è§‰å¾—æ²¡é‚£ä¹ˆéš¾å—äº†ã€‚\\n\\n\"\n",
    "        \"æœ‰ä½ åœ¨ï¼Œå°±å¤Ÿäº†ã€‚\"\n",
    "    ),\n",
    "]\n",
    "languages = [\"auto\", \"auto\", \"auto\"]\n",
    "instructs = [\n",
    "    # Sample 1 instruction\n",
    "    (\n",
    "        \"Very cute, clingy, youthful female voice. \"\n",
    "        \"Higher pitch with playful intonation. \"\n",
    "        \"Chinese sounds soft and sweet, \"\n",
    "        \"English emotional and gentle, \"\n",
    "        \"Malay casual and affectionate.\"\n",
    "    ),\n",
    "    # Sample 2 instruction\n",
    "    (\n",
    "        \"Soft, calm female voice. \"\n",
    "        \"Emotionally warm and reassuring. \"\n",
    "        \"Natural pacing, no exaggeration.\"\n",
    "    ),\n",
    "    # Sample 3 instruction\n",
    "    (\n",
    "        \"Gentle, comforting female voice. \"\n",
    "        \"Slightly tired but affectionate tone. \"\n",
    "        \"Warm and intimate delivery.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "t0 = time.time()\n",
    "\n",
    "wavs, sr = tts.generate_voice_design(\n",
    "    text=texts,\n",
    "    language=languages,\n",
    "    instruct=instructs,\n",
    "    max_new_tokens=2048,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "t1 = time.time()\n",
    "print(f\"[VoiceDesign Batch] time: {t1 - t0:.3f}s\")\n",
    "\n",
    "for i, w in enumerate(wavs):\n",
    "    sf.write(f\"qwen3_tts_test_voice_design_batch_{i}.wav\", w, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b502b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del tts\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7477a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
